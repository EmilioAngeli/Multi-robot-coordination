{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.8.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import operator\n",
    "import copy\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import operator\n",
    "import copy\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pygame\n",
    "import traceback\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# import NN layers and other componenets.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt # for plotting data and creating different charts.\n",
    "import numpy as np # for math and arrays\n",
    "import pandas as pd # data from for the data.\n",
    "import seaborn as sns # for plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Node class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    #PA, robots, grid, env, n_to_pa, free_panels, current_insp_robot, current_rech_robot, urgencies, t\n",
    "\n",
    "    \n",
    "    def __init__(self, PA, robots, C, grid, max_steps = None, env = None, n_to_pa=None, free_panels=None, current_insp_robot=None, current_rech_robot=None, urgencies=None, t=None, initializing = False):\n",
    "\n",
    "        if initializing is True:\n",
    "            self.C = C\n",
    "            self.max_steps = max_steps\n",
    "            self.t = 0\n",
    "            self.n = len(grid)\n",
    "            self.robots = robots\n",
    "            self.PA = {}\n",
    "            for p in PA:  #initializing the priority of each panel as 0\n",
    "                p = tuple(p)\n",
    "                self.PA[p] = 0\n",
    "            self.grid = grid\n",
    "            self.n = len(grid)\n",
    "            \n",
    "            #DICTIONARYIES (for time simulation, keys are time instants)\n",
    "            self.free_panels = {}\n",
    "            self.current_insp_robot = {}\n",
    "            self.current_rech_robot = {}\n",
    "            self.env = {}\n",
    "            #set for 3700 iterations\n",
    "            for i in range(2*max_steps):\n",
    "                self.env[i] = [{},{}]\n",
    "                self.current_insp_robot[i] = []\n",
    "                #the recharging robots are initialized to be available in any time instant:\n",
    "                self.current_rech_robot[i] = []\n",
    "                for r in self.robots:\n",
    "                    if self.robots[r][3] == 'r':\n",
    "                        self.current_rech_robot[i].append(r) \n",
    "                        self.env[i][0][r] = robots[r]\n",
    "                self.free_panels[i] = []\n",
    "                for p in PA:\n",
    "                    self.free_panels[i].append(tuple(p))    \n",
    "        else:\n",
    "            self.C = C\n",
    "            self.max_steps = max_steps\n",
    "            self.robots = robots\n",
    "            self.PA = PA\n",
    "            self.env = env\n",
    "            self.free_panels = free_panels#\n",
    "            self.current_insp_robot = current_insp_robot\n",
    "            self.current_rech_robot = current_rech_robot\n",
    "            self.t = t  #quando parte l'azione dopo (l'azione prima finisce a t-1)\n",
    "            self.grid = grid \n",
    "            self.n_to_pa = n_to_pa        \n",
    "            self.urgencies = urgencies\n",
    "            self.n = len(grid)\n",
    "           \n",
    "    \n",
    "    def initialize_env(self): \n",
    "        # This method returns the dictionary x: the keys are time instants while the values are lists \n",
    "        # [robots, panels], in this way is stored the situation of robots and panels at any time instant.\n",
    "        \n",
    "        C = self.C\n",
    "        \n",
    "        #OBSERVATIONS: \n",
    "        # - this method is implemented supposing that n. of panels is >= n. of robots,\n",
    "        # - initially every inspecting robot goes to the nearest solar panel \n",
    "        #   not chosen by some other inspecting robot yet.\n",
    "        panel_to_insp = {} #this is a dictionary: key = robot, value = panel to inspect.\n",
    "        d = {}\n",
    "        z = 0\n",
    "        for r in self.robots:\n",
    "            if self.robots[r][3] == 'i':\n",
    "                z += 1 # z is the number of inspecting robots\n",
    "                for p in self.PA:\n",
    "                    d[(r,p)] = np.sqrt((self.robots[r][0]-p[0])**2 + (self.robots[r][1]-p[1])**2)\n",
    "        chosen_r = []\n",
    "        chosen_p = []\n",
    "        while d != {} and len(chosen_r) < min(z+1,len(self.PA)):\n",
    "            couple = min(d.items(), key = operator.itemgetter(1))[0]\n",
    "            d.pop(couple)\n",
    "            if couple[0] not in chosen_r and couple[1] not in chosen_p:\n",
    "                panel_to_insp[couple[0]] = couple[1]\n",
    "                chosen_r.append(couple[0])\n",
    "                chosen_p.append(couple[1])\n",
    "                \n",
    "        #self.free_panels = [pa for pa in self.PA if pa not in chosen_p]\n",
    "        \n",
    "        #compute the path of each inspecting robot:\n",
    "        paths = {}\n",
    "        for r in panel_to_insp:\n",
    "            paths[r] = self.path_i(self.robots[r][0:2], panel_to_insp[r], 0)\n",
    "            for i in range(len(paths[r])):\n",
    "                self.free_panels[i].remove(panel_to_insp[r])\n",
    "            \n",
    "        max_path_length = max([len(paths[r]) for r in paths])\n",
    "        \n",
    "        #adjourn the environment for the next steps:\n",
    "        for i in range(max_path_length):\n",
    "            robots = {}\n",
    "            panels = {}\n",
    "            \n",
    "            #adjourning robots\n",
    "            for r in paths:\n",
    "                if i < len(paths[r]):\n",
    "                    robots[r] = [*paths[r][i], C-i, 'i']\n",
    "            \n",
    "            #adjourning panels\n",
    "            for pa in self.PA:\n",
    "                #the priority of the panel is augmented by 1\n",
    "                if  i == 0:\n",
    "                    panels = self.PA\n",
    "                    #robot = self.robots\n",
    "                for r in paths:\n",
    "                    if self.be_neighbours(paths[r][-1], pa):\n",
    "                        if 0 < i < len(paths[r]):\n",
    "                            panels[pa] = self.env[i-1][1][pa] + 1\n",
    "                        if i == len(paths[r]) - 1:\n",
    "                            panels[pa] = 0\n",
    "                if i > 0 and pa in self.free_panels[i]:\n",
    "                    panels[pa] = self.env[i-1][1][pa] + 1\n",
    "            self.env[i] = [robots, panels]\n",
    "            \n",
    "            #the recharging robots stay steel at least until the longest path is completed\n",
    "            for r in self.robots:\n",
    "                if self.robots[r][3] == 'r':\n",
    "                    self.env[i][0][r] = self.robots[r]\n",
    "            \n",
    "        for r in paths:\n",
    "            self.current_insp_robot[len(paths[r])].append(r)\n",
    "            \n",
    "            \n",
    "        \n",
    "        next_t = min([i for i in self.current_insp_robot.keys() if self.current_insp_robot[i] != []]) \n",
    "\n",
    "\n",
    "        next_env = copy.deepcopy(self.env)\n",
    "        next_current_insp_robot = copy.deepcopy(self.current_insp_robot)\n",
    "        next_current_rech_robot = copy.deepcopy(self.current_rech_robot)\n",
    "        next_free_panels = copy.deepcopy(self.free_panels)\n",
    "        \n",
    "        next_urgencies = 0\n",
    "        for i in range(next_t):\n",
    "            for panel in self.env[i][1]:\n",
    "                next_urgencies -= (self.env[i][1][panel])**2\n",
    "\n",
    "        for i in range(0, next_t-1): \n",
    "            next_env.pop(i, None)\n",
    "            next_current_insp_robot.pop(i, None)\n",
    "            next_current_rech_robot.pop(i, None)\n",
    "            next_free_panels.pop(i, None)                \n",
    "        \n",
    "        \n",
    "        return next_t, next_env, next_current_insp_robot, next_current_rech_robot, next_free_panels, next_urgencies\n",
    "        \n",
    "    \n",
    "    def bring_to_start(self, total_t):\n",
    "        t = copy.deepcopy(self.t)\n",
    "        self.t = 1\n",
    "        self.urgencies = 0\n",
    "        new_env, new_free_panels, new_current_insp_robot, new_current_rech_robot = {}, {}, {}, {}\n",
    "        \n",
    "        for i in self.env:\n",
    "            new_env[i-t+1] =  self.env[i]\n",
    "            \n",
    "        key_list = list(self.env.keys())\n",
    "        key_list.sort()\n",
    "        last_t = copy.copy(key_list[-1])\n",
    "        \n",
    "        for i in self.free_panels:\n",
    "            new_free_panels[i-t+1] =  self.free_panels[i]\n",
    "        for i in self.current_insp_robot:\n",
    "            new_current_insp_robot[i-t+1] =  self.current_insp_robot[i]\n",
    "        for i in self.current_rech_robot:\n",
    "            new_current_rech_robot[i-t+1] =  self.current_rech_robot[i]\n",
    "            \n",
    "        for i in range(total_t):\n",
    "            if i not in new_env:\n",
    "                new_env[i] = [{},{}]\n",
    "            if i not in new_current_insp_robot:\n",
    "                new_current_insp_robot[i] = []\n",
    "            if i not in new_current_rech_robot:\n",
    "                new_current_rech_robot[i] = []\n",
    "                for r in self.robots:\n",
    "                    if self.robots[r][3] == 'r':\n",
    "                        new_current_rech_robot[i].append(r) \n",
    "                        new_env[i][0][r] = self.env[last_t][0][r]\n",
    "            if i not in new_free_panels:          \n",
    "                self.free_panels[i] = []\n",
    "                for p in self.PA:\n",
    "                    self.free_panels[i].append(tuple(p))     \n",
    "        \n",
    "        \n",
    "        self.env, self.free_panels, self.current_insp_robot, self.current_rech_robot = new_env, new_free_panels, new_current_insp_robot, new_current_rech_robot\n",
    "        \n",
    "     \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def PA_(self):\n",
    "        return self.PA\n",
    "\n",
    "    def robots_(self):\n",
    "        return self.robots\n",
    "    \n",
    "    def C_(self):\n",
    "        return self.C\n",
    "\n",
    "    def grid_(self):\n",
    "        return self.grid\n",
    "    \n",
    "    def max_steps_(self):\n",
    "        return self.max_steps\n",
    "    \n",
    "    def n_to_pa_(self):\n",
    "        return self.n_to_pa\n",
    "    \n",
    "    def pa_to_n_(self):\n",
    "        pa_to_n = {}\n",
    "        h = 1\n",
    "        for p in self.PA:\n",
    "            p = tuple(p)\n",
    "            pa_to_n[p] = h\n",
    "            h += 1\n",
    "        return pa_to_n\n",
    "    \n",
    "\n",
    "    \n",
    "    def initial_panel(self):\n",
    "        #print('Starting panel situation:')\n",
    "        #print(self.env[1][1])\n",
    "        return self.env[1][1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    def visualize(self, i):\n",
    "        printa = copy.deepcopy(self.grid)\n",
    "        env = self.env[i]\n",
    "        for r in env[0]:\n",
    "            printa[env[0][r][0]][env[0][r][1]] = r\n",
    "        for v in printa: \n",
    "            print(v)\n",
    "            \n",
    "            \n",
    "    def path_i(self,start, goal, t):  \n",
    "        #FASTER AND OPTIMAL\n",
    "        #this method returns the shortest path (while a* does not always do) the starting tile is included,\n",
    "        #the last tile is a tile next to the target panel (goal)\n",
    "        start, goal = tuple(start), tuple(goal)\n",
    "        visited = set()\n",
    "        parent = {}\n",
    "        parent[start] = None\n",
    "        current_tiles = [start]\n",
    "        k = t\n",
    "        start_time = time.time()\n",
    "        while goal not in current_tiles:\n",
    "            if time.time() - start_time > 0.1:\n",
    "                return 'Too_long'\n",
    "            frontier = [] \n",
    "            for current_tile in current_tiles:\n",
    "                i, j = current_tile[0], current_tile[1]\n",
    "                for new_position in [(0, -1), (0, 1), (-1, 0), (1, 0), (-1, -1), (-1, 1), (1, -1), (1, 1)]: # Adjacent squares\n",
    "                    # Get node position\n",
    "                    neighb = (i + new_position[0], j + new_position[1])\n",
    "                    # Make sure within range\n",
    "                    if neighb[0] > (self.n - 1) or neighb[0] < 0 or neighb[1] > (self.n -1) or neighb[1] < 0:\n",
    "                        continue\n",
    "                    # Make sure walkable terrain\n",
    "                    if neighb in visited or (self.grid[neighb[0]][neighb[1]] != '__' and neighb != goal):\n",
    "                        continue\n",
    "                    # Make sure not crushing with other robots:\n",
    "                    crush = False\n",
    "                    for robot in self.env[k][0]:\n",
    "                        if self.env[k][0][robot][0] == neighb[0] and self.env[k][0][robot][1] == neighb[1]:\n",
    "                            crush = True\n",
    "                            continue\n",
    "                    if neighb != start:\n",
    "                        parent[neighb] = current_tile\n",
    "                    if not crush:\n",
    "                        frontier.append(neighb)\n",
    "                        visited.add(neighb)\n",
    "            #reset the current_tiles set as the new frontier:\n",
    "            current_tiles = frontier\n",
    "            k += 1\n",
    "        path = []\n",
    "        current_tile = goal\n",
    "        while parent[current_tile] is not None:\n",
    "            path.append(parent[current_tile]) \n",
    "            current_tile = parent[current_tile]\n",
    "        path.reverse()\n",
    "        return path\n",
    "    \n",
    "    \n",
    "    \n",
    "    def path_r(self, insp, rech, t):   #same idea as before but this time with 2 robots\n",
    "        #insp and rech are the starting positions of the inspecting and the recharging robot, respectively.\n",
    "        #this method returns 2 paths: the first is for the insp rob and the second for the recharging rob.\n",
    "        #the starting tiles are included\n",
    "        insp, rech = tuple(insp), tuple(rech)\n",
    "        visited_insp = set()\n",
    "        visited_rech = set()\n",
    "        parent = {}\n",
    "        parent[insp] = None\n",
    "        parent[rech] = None\n",
    "        current_insp, current_rech = [insp], [rech]\n",
    "        \n",
    "        for x in [(0, -1), (0, 1), (-1, 0), (1, 0), (-1, -1), (-1, 1), (1, -1), (1, 1)]: \n",
    "                    if insp == (rech[0] + x[0], rech[1] + x[1]): #then the robots are already next to each other\n",
    "                        return [insp], [rech]\n",
    "        \n",
    "        k = t\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            frontier_insp, frontier_rech = [], []\n",
    "            if time.time() - start_time > 0.1:\n",
    "                return 'Too_long'\n",
    "            #THE INSPECTING FRONTIER\n",
    "            for current_tile in current_insp:\n",
    "                i, j = current_tile[0], current_tile[1]\n",
    "                for new_position in [(0, -1), (0, 1), (-1, 0), (1, 0), (-1, -1), (-1, 1), (1, -1), (1, 1)]: # Adjacent square\n",
    "                    neighb = (i + new_position[0], j + new_position[1])\n",
    "                    # Make sure within range\n",
    "                    if neighb[0] > (self.n - 1) or neighb[0] < 0 or neighb[1] > (self.n -1) or neighb[1] < 0:\n",
    "                        continue\n",
    "                    # Make sure walkable terrain\n",
    "                    if neighb in visited_insp or self.grid[neighb[0]][neighb[1]] != '__':\n",
    "                        continue\n",
    "                    # Make sure not crushing with other robots:\n",
    "                    crush = False\n",
    "                    for robot in self.env[k][0]:\n",
    "                        if self.env[k][0][robot][0] == neighb[0] and self.env[k][0][robot][1] == neighb[1]:\n",
    "                            crush = True\n",
    "                            continue\n",
    "                        \n",
    "                        \n",
    "                    #ARRESTING CRITERIUM:\n",
    "                    if neighb in visited_rech:\n",
    "                        insp_path, rech_path = [current_tile], [neighb]\n",
    "                        #constructing the path of the inspecting robot:\n",
    "                        while parent[current_tile] is not None:\n",
    "                            insp_path.append(parent[current_tile]) \n",
    "                            current_tile = parent[current_tile]\n",
    "                        insp_path.reverse()\n",
    "                        #constructing the path of the recharging robot:\n",
    "                        while parent[neighb] is not None:\n",
    "                            rech_path.append(parent[neighb]) \n",
    "                            neighb = parent[neighb]\n",
    "                        rech_path.reverse()\n",
    "                        return insp_path, rech_path\n",
    "                        \n",
    "                    \n",
    "                    if neighb != insp:\n",
    "                        parent[neighb] = current_tile\n",
    "                    \n",
    "                    if not crush:\n",
    "                        frontier_insp.append(neighb)\n",
    "                        visited_insp.add(neighb)\n",
    "                        \n",
    "            k += 1           \n",
    "            #reset the current_tiles set as the new frontier for the inspecting robot:\n",
    "            current_insp = frontier_insp\n",
    "            \n",
    "            #THE RECHARGING FRONTIER\n",
    "            for current_tile in current_rech:\n",
    "                i, j = current_tile[0], current_tile[1]\n",
    "                for new_position in [(0, -1), (0, 1), (-1, 0), (1, 0), (-1, -1), (-1, 1), (1, -1), (1, 1)]: # Adjacent squares\n",
    "                    # Get node position\n",
    "                    neighb = (i + new_position[0], j + new_position[1])\n",
    "                    # Make sure within range\n",
    "                    if neighb[0] > (self.n - 1) or neighb[0] < 0 or neighb[1] > (self.n -1) or neighb[1] < 0:\n",
    "                        continue\n",
    "                    # Make sure walkable terrain\n",
    "                    if neighb in visited_rech or self.grid[neighb[0]][neighb[1]] != '__':\n",
    "                        continue\n",
    "                    # Make sure not crushing with other robots:\n",
    "                    crush = False\n",
    "                    for robot in self.env[k][0]:\n",
    "                        if self.env[k][0][robot][0] == neighb[0] and self.env[k][0][robot][1] == neighb[1]:\n",
    "                            crush = True\n",
    "                            continue   \n",
    "                        \n",
    "                    #ARRESTING CRITERIUM:\n",
    "                    if neighb in visited_insp:\n",
    "                        rech_path, insp_path = [current_tile], [neighb]\n",
    "                        #constructing the path of the inspecting robot:\n",
    "                        while parent[current_tile] is not None:\n",
    "                            rech_path.append(parent[current_tile]) \n",
    "                            current_tile = parent[current_tile]\n",
    "                        rech_path.reverse()\n",
    "                        #constructing the path of the recharging robot:\n",
    "                        while parent[neighb] is not None:\n",
    "                            insp_path.append(parent[neighb]) \n",
    "                            neighb = parent[neighb]\n",
    "                        insp_path.reverse()\n",
    "                        return insp_path, [*rech_path, rech_path[-1]] #in this way the paths have the same length\n",
    "                         \n",
    "                    if neighb != rech:\n",
    "                        parent[neighb] = current_tile\n",
    "                    \n",
    "                    if not crush:\n",
    "                        frontier_rech.append(neighb)\n",
    "                        visited_rech.add(neighb)\n",
    "                      \n",
    "            k += 1   \n",
    "            #reset the current_tiles set as the new frontier for the recharging robot:\n",
    "            current_rech = frontier_rech\n",
    "        \n",
    "\n",
    "    def be_neighbours(self, a, b): #2 positions are expected, it returns True if a and b are neighbours\n",
    "        a, b = tuple(a), tuple(b)\n",
    "        for new_position in [(0, -1), (0, 1), (-1, 0), (1, 0), (-1, -1), (-1, 1), (1, -1), (1, 1)]: \n",
    "            neighb = (a[0] + new_position[0], a[1] + new_position[1])\n",
    "            if neighb == b:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def current_insp(self, i = None):\n",
    "        if i is None:\n",
    "            return self.current_insp_robot[self.t] \n",
    "        return self.current_insp_robot[i]\n",
    "        \n",
    "    def current_rech(self): \n",
    "        return self.current_rech_robot[self.t]\n",
    "\n",
    "    def current_env(self, t): \n",
    "        return self.env[t] \n",
    "\n",
    "    def current_t(self): \n",
    "        return self.t \n",
    "\n",
    "    \n",
    "    \n",
    "    def compute_hl(self, rob, action, wait_one = False):  \n",
    "        # It returns the environment after the moove, its output needs to be usable by itself in order\n",
    "        # to compute the successive action.\n",
    "        \n",
    "        t = self.t \n",
    "        C = self.C\n",
    "        total_t =  2 * self.max_steps \n",
    "        \n",
    "        #INITIAL CHECKS:\n",
    "        \n",
    "        \n",
    "        if wait_one: # i.e. if no one of the current insp rob can do something\n",
    "            \n",
    "\n",
    "            \n",
    "            ############### Errore\n",
    "            vediamo = [i for i in self.current_insp_robot.keys() if (self.current_insp_robot[i] != [] and i > t)]\n",
    "            if vediamo == []:\n",
    "                next_t = t+1\n",
    "            else:\n",
    "                next_t = min(vediamo)\n",
    "                \n",
    "                        \n",
    "            next_current_insp_robot = copy.deepcopy(self.current_insp_robot)\n",
    "            next_current_insp_robot[next_t] = [* self.current_insp_robot[t], *next_current_insp_robot[next_t]]\n",
    "            next_current_rech_robot = copy.deepcopy(self.current_rech_robot)\n",
    "            next_free_panels = copy.deepcopy(self.free_panels)\n",
    "            next_urgencies = copy.deepcopy(self.urgencies)\n",
    "            \n",
    "            \n",
    "            for i in range(t, next_t):\n",
    "                for r in next_current_insp_robot[t]:\n",
    "                    self.env[i][0][r] = self.env[t-1][0][r]\n",
    "                for panel in self.env[i][1]:\n",
    "                    next_urgencies -= (self.env[i][1][panel])**2\n",
    "            \n",
    "            next_env = copy.deepcopy(self.env)\n",
    "            for i in range(t-1, next_t-1): \n",
    "                next_env.pop(i, None)\n",
    "                next_current_insp_robot.pop(i, None)\n",
    "                next_current_rech_robot.pop(i, None)\n",
    "                next_free_panels.pop(i, None)            \n",
    "\n",
    "            return next_t, next_env, next_current_insp_robot, next_current_rech_robot, next_free_panels, next_urgencies\n",
    "\n",
    "        \n",
    "\n",
    "        # If the robot available at time t are more than 1 (rare eventuality) we compute the choice \n",
    "        # only for one (the first) of them and posticipate the choice for the others to the next time step.\n",
    "        if len(self.current_insp_robot[t]) > 1:\n",
    "            to_inser = []\n",
    "            for rob_ in self.current_insp_robot[t]: \n",
    "                if rob_ != rob and rob_ not in self.current_insp_robot[t+1]:\n",
    "                    to_inser.append(rob_)\n",
    "                    self.env[t][0][rob_] = self.env[t-1][0][rob_]\n",
    "                    self.env[t][0][rob_][2] = max(self.env[t-1][0][rob_][2] -1, 0)\n",
    "            self.current_insp_robot[t+1] = [*to_inser, *self.current_insp_robot[t+1]] \n",
    "                    \n",
    "        # If all the inspecting robots become available in same t, then we need to adjourn the solar panels.\n",
    "        if len(self.current_insp_robot[t]) == len([r for r in self.robots if self.robots[r][3] == 'i']):\n",
    "            for pa in self.env[t-1][1]:\n",
    "                self.env[t][1][pa] = self.env[t-1][1][pa] + 1\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            if action != 0:\n",
    "                PA_to_inspect = self.n_to_pa[action]\n",
    "                path = self.path_i(self.env[t-1][0][rob][0:2], PA_to_inspect, t)[1:] \n",
    "\n",
    "                # adjourning self.free_panels:\n",
    "                for i in range(t+1, t+len(path)):\n",
    "                    if PA_to_inspect in self.free_panels[i]: \n",
    "                        self.free_panels[i].remove(PA_to_inspect)\n",
    "\n",
    "                # SPECIAL CASE: the inspecting robot is already next to the panel to inspect\n",
    "                if self.be_neighbours(self.env[t-1][0][rob][0:2],PA_to_inspect):\n",
    "                    self.env[t][0][rob] = self.env[t-1][0][rob]\n",
    "                    self.env[t][0][rob][2] = max(self.env[t][0][rob][2]-1, 0)\n",
    "                    self.current_insp_robot[t+1].append(rob)\n",
    "                    self.env[t][1][PA_to_inspect] = 0\n",
    "                    for pa in self.PA:\n",
    "                        if pa not in self.env[t+1][1]:\n",
    "                            self.env[t+1][1][pa] = self.env[t][1][pa] + 1   \n",
    "                    j = copy.copy(t+1)\n",
    "                    while PA_to_inspect in self.env[j][1]:\n",
    "                        self.env[j][1][PA_to_inspect] = j - t \n",
    "                        j += 1\n",
    "                    break\n",
    "\n",
    "                # arrived here the panel and the recharger are not next to eachother\n",
    "                last_C = self.env[t-1][0][rob][2]\n",
    "                for i in range(t, t+len(path)): \n",
    "\n",
    "                    #adjourning panels:\n",
    "                    for pa in self.PA:\n",
    "                        if pa not in self.env[i][1]:\n",
    "                            self.env[i][1][pa] = self.env[i-1][1][pa] + 1           \n",
    "\n",
    "                    #adjourning current robot:\n",
    "                    self.env[i][0][rob] = [*path[i-t], max(last_C-(i-t)-1, 0 ), 'i']\n",
    "\n",
    "                    #if the robot is discharged before of the finish of the action:\n",
    "                    if self.env[i][0][rob][2] <= 0 and i < t+len(path)-1:\n",
    "                        self.current_insp_robot[i+1].append(rob)\n",
    "                        for j in range(i,t+len(path)):\n",
    "                            self.free_panels[j].append(PA_to_inspect)                    \n",
    "                        break\n",
    "\n",
    "                    #instructions to finish the action:\n",
    "                    if i == t+len(path)-1:\n",
    "                        self.env[i][1][PA_to_inspect] = 0\n",
    "                        j = i+1\n",
    "                        while PA_to_inspect in self.env[j][1]:\n",
    "                            self.env[j][1][PA_to_inspect] = j - i\n",
    "                            j += 1\n",
    "                        self.current_insp_robot[i+1].append(rob)\n",
    "    \n",
    "                break\n",
    "            ###############################################################################################\n",
    "            # ACTION 0: go recharge.\n",
    "            \n",
    "            \n",
    "            #SPECIAL CASE: the insp rob is already next to a recharger.\n",
    "            if action == 0:\n",
    "                interrupt = False\n",
    "                for rech in self.env[t-1][0]:\n",
    "                    if self.env[t-1][0][rech][3] == 'r' and self.be_neighbours(self.env[t-1][0][rob][0:2],self.env[t-1][0][rech][0:2]) and rech in self.current_rech_robot[t]:\n",
    "                        self.env[t][0][rob] = self.env[t-1][0][rob]\n",
    "                        self.env[t][0][rob][2] = C\n",
    "                        self.current_rech_robot[t].remove(rech)\n",
    "                        self.current_insp_robot[t+1].append(rob)\n",
    "                        for pa in self.PA:\n",
    "                            if pa not in self.env[t+1][1]:\n",
    "                                self.env[t+1][1][pa] = self.env[t][1][pa] + 1    \n",
    "                        interrupt = True \n",
    "                        break      \n",
    "                if interrupt:\n",
    "                    break\n",
    "                    \n",
    "            #FIRST CASE: the inspecting robot is not discharged yet, both the insp and the rech moove toward each others.\n",
    "            if action == 0 and self.env[t-1][0][rob][2] > 0:\n",
    "\n",
    "                # The distance is evaluated in terms of length of the path needed: \n",
    "                # we consider the possible presence of obs\n",
    "                rech = self.current_rech_robot[t][0]\n",
    "                path = self.path_r(self.env[t-1][0][rob][0:2],self.env[t-1][0][rech][0:2], t)\n",
    "                rob_path = path[0][1:]                \n",
    "                rech_path = path[1][1:]\n",
    "                \n",
    "                if len(self.current_rech_robot[t]) > 1:\n",
    "                    for i in range(1,len(self.current_rech_robot[t])):\n",
    "                        rech_ = self.current_rech_robot[t][i]\n",
    "                        path_ = self.path_r(self.env[t-1][0][rech][0:2], self.env[t-1][0][rob][0:2], t)[1:]\n",
    "                        rob_path_ = path_[0][0][1:]                \n",
    "                        rech_path_ = path_[0][1][1:]\n",
    "                        if len(path_) < len(path):\n",
    "                            rech, rob_path, rech_path = rech_, rob_path_, rech_path_\n",
    "                                        \n",
    "                \n",
    "                last_C = self.env[t-1][0][rob][2]\n",
    "                for i in range(t, t+len(rob_path)):\n",
    "\n",
    "                    #adjourning involved robots:\n",
    "                    self.env[i][0][rob] = [*rob_path[i-t], max(last_C-(i-t)-1, 0),'i']\n",
    "                    self.env[i][0][rech] = [*rech_path[i-t], -1, 'r']\n",
    "\n",
    "                    #the current recharging robot is occupied now:\n",
    "                    self.current_rech_robot[i].remove(rech)\n",
    "\n",
    "                    #adjourning panels:\n",
    "                    for pa in self.PA:\n",
    "                        if pa not in self.env[i][1]:\n",
    "                            self.env[i][1][pa] = self.env[i-1][1][pa] + 1    \n",
    "\n",
    "                    #if the robot is discharged before of the finish of the action:\n",
    "                    if self.env[i][0][rob][2] <= 0 and i < t+len(rob_path)-1:\n",
    "                        self.current_insp_robot[i+1].append(rob)\n",
    "                        for j in range(i, total_t):\n",
    "                            self.env[j][0][rech] = self.env[j][0][rech]\n",
    "                        break\n",
    "\n",
    "                    #instructions to finish the action:\n",
    "                    if i == t+len(rob_path)-1:\n",
    "                        self.current_insp_robot[i+1].append(rob)\n",
    "                        self.env[i][0][rob][2] = C\n",
    "\n",
    "                for i in range(t+len(rob_path)-1, total_t): \n",
    "                    self.env[i][0][rech] = self.env[t+len(rob_path)-1][0][rech]\n",
    "                \n",
    "                break \n",
    "                \n",
    "            #SECOND CASE: the inspecting robot is discharged, the recharged robot needs to reach it.\n",
    "            if action == 0 and self.env[t-1][0][rob][2] <= 0:\n",
    "                # The distance is evaluated in terms of length of the path needed: \n",
    "                \n",
    "                # qui \n",
    "                rech = self.current_rech_robot[t][0]\n",
    "                \n",
    "                \n",
    "                \n",
    "                path = self.path_i(self.env[t-1][0][rech][0:2], self.env[t-1][0][rob][0:2], t)[1:]\n",
    "                if len(self.current_rech_robot[t]) > 1:\n",
    "                    for i in range(1,len(self.current_rech_robot[t])):\n",
    "                        rech_ = self.current_rech_robot[t][i]\n",
    "                        path_ = self.path_i(self.env[t-1][0][rech][0:2], self.env[t-1][0][rob][0:2], t)[1:]\n",
    "                        if len(path_) < len(path):\n",
    "                            rech, path = rech_, path_\n",
    "                            \n",
    "                        \n",
    "                last_C = self.env[t-1][0][rob][2]\n",
    "                for i in range(t, t+len(path)):\n",
    "\n",
    "                    #adjourning involved robots:\n",
    "                    \n",
    "                    self.env[i][0][rob] = [*self.env[t-1][0][rob][0:2], max(last_C-(i-t)-1,0),'i']\n",
    "                    self.env[i][0][rech] = [*path[i-t], -1, 'r']\n",
    "\n",
    "                    #the current recharging robot is occupied now:\n",
    "                    self.current_rech_robot[i].remove(rech)\n",
    "\n",
    "                    #adjourning panels:\n",
    "                    for pa in self.PA:\n",
    "                        if pa not in self.env[i][1]:\n",
    "                            self.env[i][1][pa] = self.env[i-1][1][pa] + 1    \n",
    "\n",
    "                    #instructions to finish the action:\n",
    "                    if i == t+len(path)-1:\n",
    "                        self.current_insp_robot[i+1].append(rob)\n",
    "                        self.env[i][0][rob][2] = C\n",
    "\n",
    "                for i in range(t+len(path)-1, total_t): \n",
    "                    self.env[i][0][rech] = self.env[t+len(path)-1][0][rech]\n",
    "\n",
    "                break\n",
    "                \n",
    "                \n",
    "        next_t = min([i for i in self.current_insp_robot.keys() if (self.current_insp_robot[i] != [] and i > t)])\n",
    "        next_env = copy.deepcopy(self.env)\n",
    "        next_current_insp_robot = copy.deepcopy(self.current_insp_robot)\n",
    "        next_current_rech_robot = copy.deepcopy(self.current_rech_robot)\n",
    "        next_free_panels = copy.deepcopy(self.free_panels)\n",
    "        next_urgencies = copy.deepcopy(self.urgencies)\n",
    "        \n",
    "        for i in range(t, min(self.max_steps,next_t)):  #the rewards are untill 200 time steps\n",
    "            for panel in self.env[i][1]:\n",
    "                next_urgencies -= (self.env[i][1][panel])**2\n",
    "\n",
    "        for i in range(t-1, next_t-1): \n",
    "            next_env.pop(i, None)\n",
    "            next_current_insp_robot.pop(i, None)\n",
    "            next_current_rech_robot.pop(i, None)\n",
    "            next_free_panels.pop(i, None)                \n",
    "        \n",
    "        \n",
    "        return next_t, next_env, next_current_insp_robot, next_current_rech_robot, next_free_panels, next_urgencies\n",
    "    \n",
    "   \n",
    "        \n",
    "        \n",
    "            \n",
    "    def is_allowed(self, rob, action):  # Return False when the action is not possible.\n",
    "        t = self.t\n",
    "        \n",
    "        # (1) 'go recharge' and no recharger is available\n",
    "        if action == 0 and self.current_rech_robot[t] == []: \n",
    "            return False\n",
    "        # (2) 'go inspect' and self.current_insp is discharged\n",
    "        if action != 0 and self.env[t-1][0][rob][2] <= 0:\n",
    "            return False\n",
    "        if action != 0 and self.n_to_pa[action] not in self.free_panels[t]:\n",
    "            return False\n",
    "        \n",
    "        \n",
    "        return True    \n",
    "        # OBS: no action is possible if the robot is discharged and no recharger is available.\n",
    "        \n",
    "    def make_copy(self):\n",
    "        robots = self.robots\n",
    "        PA = self.PA\n",
    "        grid = self.grid\n",
    "        n_to_pa = self.n_to_pa \n",
    "        C =self.C\n",
    "        max_steps = self.max_steps\n",
    "        \n",
    "        env = copy.deepcopy(self.env)\n",
    "        free_panels = copy.deepcopy(self.free_panels)\n",
    "        current_insp_robot = copy.deepcopy(self.current_insp_robot) \n",
    "        current_rech_robot = copy.deepcopy(self.current_rech_robot)\n",
    "        t = copy.deepcopy(self.t)    \n",
    "        urgencies = copy.deepcopy(self.urgencies)\n",
    "        \n",
    "        x = Node(PA, robots, C, grid, max_steps, env, n_to_pa, free_panels, current_insp_robot, current_rech_robot, urgencies, t, initializing = False)\n",
    "\n",
    "        return x\n",
    "        \n",
    "        \n",
    "    \n",
    "    def find_children(self, n_of_children): ##DA RICONTROLLARE\n",
    "        \n",
    "        current_available_robots = copy.copy(self.current_insp())\n",
    "        children = []#set()\n",
    "        while current_available_robots:\n",
    "            rob = copy.deepcopy(current_available_robots[0])\n",
    "            must_wait = True\n",
    "            for action in range(0, len(self.PA)+1):\n",
    "                if self.is_allowed(rob, action):\n",
    "                    try:   \n",
    "                        copia = self.make_copy()\n",
    "                        t, env, current_insp_robot, current_rech_robot, free_panels, urgencies = copia.compute_hl(rob, action)\n",
    "                    except (IndexError, ValueError, KeyError, TypeError):\n",
    "                        continue\n",
    "                    must_wait = False\n",
    "\n",
    "                    n_of_children += 1\n",
    "                    children.append((n_of_children,rob,action))   \n",
    "            if must_wait:\n",
    "                copia = self.make_copy()\n",
    "                t, env, current_insp_robot, current_rech_robot, free_panels, urgencies = copia.compute_hl(rob, action, wait_one = True)\n",
    "\n",
    "                n_of_children += 1\n",
    "                #children.add((n_of_children,rob,'wait_one'))\n",
    "                children.append((n_of_children,rob,'wait_one'))\n",
    "            current_available_robots.remove(rob)   \n",
    "        return children\n",
    "    \n",
    "    \n",
    "    def find_random_child(self, with_action = False):\n",
    "        current_available_robots = copy.copy(self.current_insp())\n",
    "        available_actions = list(range(len(self.PA) + 1))\n",
    "        index = random.randint(0,len(self.PA))\n",
    "        action = available_actions[index]\n",
    "        rob = current_available_robots[0]\n",
    "        waiting = False\n",
    "        stop = False\n",
    "        errors = 0\n",
    "        while not stop:\n",
    "            while not self.is_allowed(rob, action):\n",
    "                if not available_actions :\n",
    "                    if len(current_available_robots) == 1: \n",
    "                        t, env, current_insp_robot, current_rech_robot, free_panels, urgencies = self.compute_hl(rob, action, wait_one = True)\n",
    "                        current_available_robots.remove(rob)\n",
    "                        waiting = True\n",
    "                        stop = True\n",
    "                        break\n",
    "                    available_actions = list(range(len(self.PA) + 1))\n",
    "                    index = random.randint(0,len(self.PA))\n",
    "                    action = available_actions[index]\n",
    "                    current_available_robots.remove(rob)\n",
    "                    rob = current_available_robots[0]\n",
    "                available_actions.remove(action)\n",
    "                if available_actions:\n",
    "                    index = random.randint(0,len(available_actions)-1)\n",
    "                    action = available_actions[index]\n",
    "            if not waiting:\n",
    "                try:\n",
    "                    t, env, current_insp_robot, current_rech_robot, free_panels, urgencies = self.compute_hl(rob, action)\n",
    "                    stop = True\n",
    "                    break\n",
    "                except (IndexError, ValueError, KeyError, TypeError):\n",
    "                    errors += 1\n",
    "                    if errors > 100:\n",
    "                        return 'error'\n",
    "                    continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        node = Node(self.PA, self.robots, self.C, self.grid, self.max_steps, env, self.n_to_pa, free_panels, current_insp_robot, current_rech_robot, urgencies, t)\n",
    "        #(self, PA, robots, C, grid, max_steps = None, env = None, n_to_pa=None, free_panels=None, current_insp_robot=None, current_rech_robot=None, urgencies=None, t=None, initializing = False):\n",
    "\n",
    "        if with_action is True:\n",
    "            return node, (rob,action)\n",
    "        return node\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    def is_terminal(self):\n",
    "        \"Returns True if the node has no children\"\n",
    "        if self.t >= self.max_steps:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def reward(self):\n",
    "        return self.urgencies\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MCTS class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "class MCTS:\n",
    "\n",
    "    def __init__(self, Q=None, N=None, best_path=None, s=None, best_reward=None, children=None, best_action_seq = None):\n",
    " #self, Q=defaultdict(int), N=defaultdict(int), best_path=[], s=[], best_reward=-math.inf, children={}):\n",
    "        \n",
    "        if Q is None:\n",
    "            Q = defaultdict(int)\n",
    "        if N is None:\n",
    "            N = defaultdict(int)\n",
    "        if best_path is None:\n",
    "            best_path = []\n",
    "        if s is None:\n",
    "            s=[]\n",
    "        if best_reward is None:    \n",
    "            best_reward=-math.inf\n",
    "        if children is None:\n",
    "            children = {}\n",
    "        if best_action_seq is None:\n",
    "            best_action_seq = []\n",
    "    \n",
    "        self.Q = Q  # total reward of each node\n",
    "        self.N = N  # total visit count for each node\n",
    "        self.best_path = best_path\n",
    "        self.s = s\n",
    "        self.best_reward = best_reward\n",
    "        self.children = children  # children of each node\n",
    "        self.best_action_seq = best_action_seq\n",
    "        self.n_prunings = 0\n",
    "        self.n_of_children = 0 \n",
    "        \n",
    "        \n",
    "    def current_situation(self):\n",
    "        return [self.Q, self.N, self.best_path, self.s, self.best_reward, self.children]\n",
    "    \n",
    "    def best_r(self):\n",
    "        return self.best_reward\n",
    "        \n",
    "    def best_p(self):\n",
    "        return self.best_path\n",
    "   \n",
    "    def scores(self):\n",
    "        return self.s\n",
    "    \n",
    "    def best_actions(self):\n",
    "        return self.best_action_seq\n",
    "    \n",
    "    def print_n_prunings(self):\n",
    "        print('EARLY PRUNING OCCURRED ',self.n_prunings,' TIMES')\n",
    "        \n",
    "    def print_children(self):\n",
    "        print(self.children)\n",
    "    \n",
    "    def do_rollout(self, node, e_weight, NN, other_actions, model, NN_game_rate, NN_mooves_rate):\n",
    "        \"Make the tree one layer better. (Train for one iteration.)\"\n",
    "\n",
    "        \n",
    "        while True:\n",
    "            action_path = self._select(node, e_weight)\n",
    "            \n",
    "            #reconstruct path and other_actions:\n",
    "            path = [node]\n",
    "            l = node\n",
    "            other_actions1 = copy.deepcopy(other_actions)\n",
    "            \n",
    "            for k in range(1,len(action_path)):\n",
    "                \n",
    "                PA = l.PA_()\n",
    "                robots = l.robots_()\n",
    "                C = l.C_()\n",
    "                grid = l.grid_()\n",
    "                max_steps = l.max_steps_()\n",
    "                n_to_pa = l.n_to_pa_()\n",
    "                \n",
    "                \n",
    "                rob, action = action_path[k][1], action_path[k][2]\n",
    "                copia = copy.deepcopy(l)\n",
    "                if action == 'wait_one':\n",
    "                    t, env, current_insp_robot, current_rech_robot, free_panels, urgencies = copia.compute_hl(rob, action, wait_one = True)\n",
    "                else:\n",
    "                    t, env, current_insp_robot, current_rech_robot, free_panels, urgencies = copia.compute_hl(rob, action)\n",
    "                path.append(copia)        \n",
    "                l = Node(PA, robots, C, grid, max_steps, env, n_to_pa, free_panels, current_insp_robot, current_rech_robot, urgencies, t)\n",
    "\n",
    "                \n",
    "                if NN:\n",
    "                    #adjourning other_actions\n",
    "                    t = copia.current_t()\n",
    "                    previs = copia.current_env(t)\n",
    "                    durata = 0\n",
    "                    while rob in previs[0]:\n",
    "                        durata += 1\n",
    "                        previs = copia.current_env(t + durata)\n",
    "                    other_actions1[rob] = [action , t + durata]\n",
    "                \n",
    "                    \n",
    "                    \n",
    "            if len(action_path) == 1:\n",
    "                break\n",
    "            \n",
    "            if urgencies <= self.best_reward:  #  EARLY PRUNING.\n",
    "                #print('Early pruned: at heigh', len(action_path), 'the ugency =',-urgencies,'>', -self.best_reward,'= best score achived')\n",
    "                self.children[action_path[-2]].remove(action_path[-1])\n",
    "                self.n_prunings += 1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        \n",
    "        self._expand(l, action_path[-1])\n",
    "        reward = self._simulate(l, path, action_path, NN, other_actions1, model, NN_game_rate, NN_mooves_rate)\n",
    "        if reward != 'no_reward':\n",
    "            self._backpropagate(action_path, reward)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _select(self, node, e_weight):\n",
    "        \"Find an unexplored descendent of `node`\"\n",
    "        path = []\n",
    "        while True:\n",
    "            path.append(node)\n",
    "            if node not in self.children or not self.children[node]:\n",
    "                # node is either unexplored or terminal\n",
    "                return path\n",
    "            unexplored = self.children[node] - self.children.keys()\n",
    "            if unexplored:\n",
    "                n = unexplored.pop()\n",
    "                path.append(n)\n",
    "                return path\n",
    "            node = self._uct_select(node, e_weight)  # descend a layer deeper\n",
    "            \n",
    "            \n",
    "            \n",
    "    def _expand(self, leaf, action_leaf):\n",
    "        \"Update the `children` dict with the children of `node`\"\n",
    "        if leaf in self.children:# or action_leaf in self.children:\n",
    "            return  # already expanded\n",
    "        self.children[action_leaf] = leaf.find_children(self.n_of_children)\n",
    "        self.n_of_children += len(self.children[action_leaf])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _simulate(self, l, path, action_path, NN, other_actions1, model, NN_game_rate, NN_mooves_rate):\n",
    "        \"Returns the reward for a random simulation (to completion) of `node`\"\n",
    "        \n",
    "        side_path = copy.deepcopy(path)\n",
    "        side_action_path = []\n",
    "        node = copy.deepcopy(l)\n",
    "        \n",
    "        if NN and random.random() < NN_game_rate:\n",
    "\n",
    "            nodes_sequence, side_action_path, reward = NN_plays(model, node, other_actions1, NN_mooves_rate)\n",
    "            side_path += nodes_sequence\n",
    "        \n",
    "            self.s.append(reward)\n",
    "            if reward > self.best_reward:\n",
    "                self.best_reward = reward\n",
    "                self.best_path = copy.deepcopy(side_path)\n",
    "                self.best_action_seq = [a[1:] for a in action_path[1:]] + side_action_path #DA AGGIUNGERE IL RESTO DEL PATH\n",
    "\n",
    "            return reward\n",
    "        \n",
    "        \n",
    "        #it = 0\n",
    "        while True:\n",
    "            #it += 1\n",
    "            node_, action = copy.deepcopy(node.find_random_child(with_action = True))\n",
    "            \n",
    "            #if node_ == 'error':\n",
    "            #    print('Error at height:', len(path)-1, ', known tree length:', it)\n",
    "            #    self.children[action_path[-2]].remove(action_path[-1])\n",
    "            #    return 'no_reward'\n",
    "            \n",
    "            side_path.append(node)\n",
    "            side_action_path.append(action)\n",
    "            \n",
    "            if node_.is_terminal(): \n",
    "                side_path.append(node_)\n",
    "                reward = node_.reward()\n",
    "                self.s.append(reward)\n",
    "                if reward > self.best_reward:\n",
    "                    self.best_reward = reward\n",
    "                    self.best_path = copy.deepcopy(side_path)\n",
    "                    self.best_action_seq = [a[1:] for a in action_path[1:]] + side_action_path #DA AGGIUNGERE IL RESTO DEL PATH\n",
    "                    \n",
    "                return reward\n",
    "            \n",
    "            node = copy.deepcopy(node_)\n",
    "            \n",
    "            \n",
    "            \n",
    "    def _backpropagate(self, action_path, reward):\n",
    "        \"Send the reward back up to the ancestors of the leaf\"\n",
    "        for node in reversed(action_path):\n",
    "            self.N[node] += 1\n",
    "            self.Q[node] += reward\n",
    "            #if reward > self.Q[node]:\n",
    "            #    self.Q[node] = copy.copy(reward)\n",
    "            \n",
    "\n",
    "    def _uct_select(self, node, e_weight):\n",
    "        \"Select a child of node, balancing exploration & exploitation\"\n",
    "        # All children of node should already be expanded:\n",
    "        assert all(n in self.children for n in self.children[node])\n",
    "        log_N_vertex = math.log(self.N[node]+1)\n",
    "        def uct(n):   \n",
    "            \"Upper confidence bound for trees\"\n",
    "            return self.Q[n] / (self.N[n]+1) + e_weight * math.sqrt(log_N_vertex / (self.N[n]+1))\n",
    "        return max(self.children[node], key=uct)\n",
    "    \n",
    "    def do_grid(self, n, PA, obstacles):\n",
    "        w = [['__']*n]*n    \n",
    "        w = np.array(w)\n",
    "        for l in PA:#adding the solar panel\n",
    "            w[l[0]][l[1]] = 'PA'\n",
    "        for obs in obstacles:#adding the solar panel\n",
    "            w[obs[0]][obs[1]] = '**'\n",
    "        grid = w\n",
    "        return grid\n",
    "\n",
    "    def n_to_pa_(self, PA, fitt = 0):\n",
    "        # We assign one and only one number to each panel:\n",
    "        n_to_pa = {}\n",
    "        pa_to_n = {}\n",
    "        h = 1\n",
    "        for p in PA:\n",
    "            p = tuple(p)\n",
    "            n_to_pa[h] = p\n",
    "            pa_to_n[p] = h\n",
    "            h += 1\n",
    "        if fitt == 0:\n",
    "            return n_to_pa\n",
    "        else:\n",
    "            return pa_to_n\n",
    "        \n",
    "    def find_random_start(self, C, n, PA, obstacles, robots, max_steps, with_current_actions = False):\n",
    "        \n",
    "        grid = self.do_grid(n, PA, obstacles)\n",
    "        n_to_pa = self.n_to_pa_(PA)\n",
    "        total_t = 3*max_steps\n",
    "        nox = Node(PA, robots, C, grid, max_steps, initializing = True)\n",
    "        t, env, current_insp_robot, current_rech_robot, free_panels, urgencies = nox.initialize_env()\n",
    "        node = Node(PA, robots, C, grid, max_steps, env, n_to_pa, free_panels, current_insp_robot, current_rech_robot, urgencies, t)\n",
    "    \n",
    "        \n",
    "        while True:\n",
    "            no = copy.deepcopy(node)\n",
    "            current_actions = {}\n",
    "            err = False\n",
    "            \n",
    "            while no.current_t() < max_steps/3:\n",
    "                                \n",
    "                copy_no = no.make_copy()\n",
    "                no_ = copy_no.find_random_child()\n",
    "                if no_ == 'error':\n",
    "                    err = True\n",
    "                    break\n",
    "                \n",
    "                if with_current_actions:\n",
    "                    \n",
    "                    copy_no = no.make_copy()\n",
    "                    no_, (rob,action) = copy_no.find_random_child(with_action = True)\n",
    "                    t = copy_no.current_t()\n",
    "                    previs = copy_no.current_env(t)\n",
    "                    durata = 0\n",
    "                    while rob in previs[0]:\n",
    "                        durata += 1\n",
    "                        previs = copy_no.current_env(t + durata)\n",
    "                    current_actions[rob] = [action , t + durata]\n",
    "                \n",
    "                no = copy.deepcopy(no_)       \n",
    "                    \n",
    "            if err == False:\n",
    "                no.bring_to_start(total_t)\n",
    "                envi = no.env[1][0]     \n",
    "                if no.env[1][1] != {}:\n",
    "                    if not with_current_actions:\n",
    "                        return no   \n",
    "                    return no, current_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def initialize_random(tree, C, n, PA, obstacles, robots, max_steps, with_current_actions = False):\n",
    "    \n",
    "    if  with_current_actions == False:\n",
    "        initial_node = tree.find_random_start(C, n, PA, obstacles, robots, max_steps)\n",
    "        #print(initial_node.initial_panel())\n",
    "        return initial_node\n",
    "    \n",
    "    initial_node, current_actions = tree.find_random_start(C, n, PA, obstacles,\n",
    "                                                           robots, max_steps, with_current_actions = True)\n",
    "    return initial_node, current_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_rollout(initial_node, n_rollouts, alpha, other_actions = None,\n",
    "               NN = False, model = None, NN_game_rate = 0.5, NN_mooves_rate = 0.9, disp = 500, pickling = True):\n",
    "    #if you want to stop before run time --> pickling =True,   scores, p, actions = depickle_and_plot()\n",
    "    \n",
    "    \n",
    "    node = copy.deepcopy(initial_node)\n",
    "    exploration_weight = 1\n",
    "    tree = MCTS()\n",
    "    tt = time.time()\n",
    "\n",
    "    for _ in range(n_rollouts):\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                \n",
    "                tree.do_rollout(node, exploration_weight, NN, other_actions, model, NN_game_rate, NN_mooves_rate)\n",
    "                break\n",
    "            except (IndexError, ValueError, KeyError, TypeError):\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        if _ < n_rollouts/10:\n",
    "            scores = tree.s\n",
    "            exploration_weight = -np.mean(scores)\n",
    "        else:\n",
    "            if -exploration_weight < max(scores)/2:\n",
    "                exploration_weight **= alpha\n",
    "\n",
    "        if _ % disp == 0:\n",
    "            print('iteration:',_,'exploration weight:', exploration_weight, ', time: ', round(time.time()-tt,1) )\n",
    "            \n",
    "            if pickling:\n",
    "                # The sequence of nodes and the sequence of actions:\n",
    "                p = tree.best_p()\n",
    "                actions = tree.best_actions()\n",
    "                scores_ = tree.scores()\n",
    "\n",
    "                # pickling p and actions:\n",
    "                pickling_on = open(\"p.pickle\",\"wb\")\n",
    "                pickle.dump(p, pickling_on)\n",
    "                pickling_on.close()\n",
    "                pickling_on = open(\"actions.pickle\",\"wb\")\n",
    "                pickle.dump(actions, pickling_on)\n",
    "                pickling_on.close()\n",
    "                pickling_on = open(\"scores.pickle\",\"wb\")\n",
    "                pickle.dump(scores_, pickling_on)\n",
    "                pickling_on.close()\n",
    "\n",
    "    print('finished in', time.time()-tt )\n",
    "    \n",
    "    \n",
    "    p = tree.best_p()\n",
    "    actions = tree.best_actions()\n",
    "    scores = tree.scores()\n",
    "    return p, actions, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depickle_and_plot(plot = True, scores = None):\n",
    "\n",
    "    \n",
    "    # depickling if not p, action, scores:\n",
    "    if scores == None:\n",
    "        pickle_off = open(\"scores.pickle\", 'rb')\n",
    "        scores = pickle.load(pickle_off)\n",
    "        pickle_off = open(\"p.pickle\", 'rb')\n",
    "        p = pickle.load(pickle_off)\n",
    "        pickle_off = open(\"actions.pickle\", 'rb')\n",
    "        actions = pickle.load(pickle_off)\n",
    "\n",
    "    if plot == True:\n",
    "        #plotting\n",
    "        plt.plot(scores, \"o\", markersize=0.55)\n",
    "        plt.title(\"Scores\")\n",
    "        plt.xlabel('rollout number')\n",
    "        plt.ylabel('Score')\n",
    "        plt.show()\n",
    "        print('Best score:', max(scores), 'achived in iteration:', np.argmax(scores))\n",
    "        #tree.print_n_prunings()\n",
    "    \n",
    "    if scores == None:\n",
    "        return p, actions, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_visualization(p, actions, total_t):\n",
    "    \n",
    "\n",
    "    xxx = 0\n",
    "    n_coppie_utili = 0\n",
    "    n_to_pa = p[1].n_to_pa_()\n",
    "    \n",
    "    for i in range(1,len(p)):\n",
    "        nodo_ = p[i]\n",
    "        nodo = p[i-1]\n",
    "        t_ = nodo_.current_t()\n",
    "        t = nodo.current_t()\n",
    "\n",
    "\n",
    "        if nodo.is_terminal():\n",
    "            break\n",
    "\n",
    "        for j in range(t,min(t_, total_t)):\n",
    "\n",
    "            if j == t:\n",
    "\n",
    "                print('###################### ',i-1 ,'-th NODE . time step:', j, '######################################') \n",
    "\n",
    "                if i < len(p)-1:\n",
    "                    action = actions[i-2]\n",
    "                    if action[1] == 'wait_one':\n",
    "                        a = 'waits'\n",
    "                    elif action[1] == 0:\n",
    "                        a = 'recharges'\n",
    "                    else:\n",
    "                        a = 'inspects panel ' + str(n_to_pa[action[1]])\n",
    "                    print('CURRENT ACTION: ', action[0], a)\n",
    "\n",
    "                    #IMPORTANT OBS: bisogna cambiare: must wait non viene capito----> check se un'azione non  possibile(--> must wait).\n",
    "                    # scartare tutte le coppie (stato, opt action) dove l'opt action non  fattibile.\n",
    "                    fitt = nodo.current_env(t-1) \n",
    "                    if a not in ['waits', 'recharges'] and fitt[0][action[0]][2] == 0:\n",
    "                        print(fitt[0][action[0]][2] )\n",
    "                        print('AZIONE NO BUENA')\n",
    "                    else:\n",
    "                        n_coppie_utili += 1\n",
    "                        #fai lo storing della coppia (nodo, action) dove action[0]  il rob e \n",
    "                        # action[1] va da 0 a len(PA) + 1\n",
    "\n",
    "            s = nodo.current_env(j)\n",
    "            print('PANELS:', s[1])\n",
    "            print('ROBOTS:', s[0])\n",
    "            nodo.visualize(j)\n",
    "            print('          ')\n",
    "            for pa in s[1]:\n",
    "                xxx += s[1][pa]**2\n",
    "\n",
    "            #CHECKING ERRORS (commented because no errors occurr)\n",
    "            if j < total_t-1:\n",
    "                if j == t_- 1:\n",
    "                    s_f = nodo_.current_env(t_)\n",
    "                else:\n",
    "                    s_f = nodo.current_env(j+1) \n",
    "                for r in s[0]:\n",
    "                    if s[0][r][0:2] != s_f[0][r][0:2]:\n",
    "                        if not nodo.be_neighbours(s[0][r][0:2], s_f[0][r][0:2]): # a robot does more than one step\n",
    "                            print(r)\n",
    "                            print('ERROR1: a robot does more than one step')\n",
    "                            sys.exit()  \n",
    "                        if s[0][r][2] == 0:  # a discharged robot mooves\n",
    "                            print(r)\n",
    "                            print('ERROR4: a discharged robot mooves')\n",
    "                            sys.exit()\n",
    "                for pa in s[1]:\n",
    "                    if s_f[1][pa] - s[1][pa] > 1:  # a panel urgency increases of more than one unit per time step\n",
    "                        print('ERROR2: a panel urgency increases of more than one unit per time step')\n",
    "                        sys.exit()\n",
    "                    if s[1][pa] == 0: # a non inspected panel's urgency becomes 0\n",
    "                        if [r for r in s[0] if s[0][r][3] == 'i' and nodo.be_neighbours(s[0][r][0:2], pa)] == []:\n",
    "                            print('ERROR3: a non inspected panel s urgency becomes 0')\n",
    "                            sys.exit()\n",
    "\n",
    "    print('TOTAL SCORE:', -xxx)\n",
    "    print('coppie utili', n_coppie_utili)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing (Pygame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#PLOTTING FUNCTION:\n",
    "def print_env(tile_size, env, time_step, gameDisplay, n, initial_node, obstacles, action=None, image_edge = 1000):#environment, j, gameDisplay, action)\n",
    "    \n",
    "    pa_to_n = initial_node.pa_to_n_()\n",
    "    PA = initial_node.PA_()\n",
    "    robots = initial_node.robots_()  \n",
    "    \n",
    "    image_edge = 1000\n",
    "    \n",
    "    #Loading images:\n",
    "    insp_rob = pygame.image.load('/home/emilio/Documents/Tesi ISR tentativi utili/immagini_env/robot2.jpg')\n",
    "    insp_rob  = pygame.transform.scale(insp_rob, (image_edge/n, image_edge/n))\n",
    "    rech_rob = pygame.image.load('/home/emilio/Documents/Tesi ISR tentativi utili/immagini_env/robot3.jpg')\n",
    "    rech_rob  = pygame.transform.scale(rech_rob, (image_edge/n, image_edge/n))\n",
    "    panel = pygame.image.load('/home/emilio/Documents/Tesi ISR tentativi utili/immagini_env/panel.png')\n",
    "    panel = pygame.transform.scale(panel, (image_edge/n, image_edge/n))\n",
    "    brick = pygame.image.load('/home/emilio/Documents/Tesi ISR tentativi utili/immagini_env/bricks.png')\n",
    "    brick = pygame.transform.scale(brick, (image_edge/n, image_edge/n))    \n",
    "    grass = pygame.image.load('/home/emilio/Documents/Tesi ISR tentativi utili/immagini_env/grass.jpeg')\n",
    "    grass = pygame.transform.scale(grass, (image_edge/n, image_edge/n))    \n",
    "    \n",
    "    gameDisplay.fill((255, 255, 255))\n",
    "    #Environment:\n",
    "    occupied = []\n",
    "    for rech in [rob for rob in env[0] if env[0][rob][3] == 'r']:\n",
    "        i,j =  env[0][rech][0:2]\n",
    "        occupied.append([i,j])\n",
    "        gameDisplay.blit(rech_rob, (j*tile_size,i*tile_size))\n",
    "    for insp in [rob for rob in env[0] if env[0][rob][3] == 'i']:\n",
    "        i,j =  env[0][insp][0:2]\n",
    "        occupied.append([i,j])\n",
    "        gameDisplay.blit(insp_rob, (j*tile_size,i*tile_size))\n",
    "        \n",
    "        font = pygame.font.SysFont('CFF', 30)\n",
    "        text = font.render(str(insp)[-1] , True, (255,0,0), (255,255,255))\n",
    "        gameDisplay.blit(text, (j*tile_size,i*tile_size))\n",
    "\n",
    "        #font = pygame.font.SysFont('CFF', 25)\n",
    "        #text = font.render(str(env[0][insp][2]), True, (0,0,0) )\n",
    "        #gameDisplay.blit(text, ((j+0.35)*tile_size,(i+0.3)*tile_size))\n",
    "    for obstacle in obstacles: \n",
    "        i, j = obstacle[0:2]\n",
    "        occupied.append([i,j])\n",
    "        gameDisplay.blit(brick, (j*tile_size,i*tile_size))\n",
    "    for pa in PA:\n",
    "        i, j = pa[0:2]\n",
    "        occupied.append([i,j])\n",
    "        gameDisplay.blit(panel, (j*tile_size,i*tile_size))\n",
    "        font = pygame.font.SysFont('CFF', 30)\n",
    "        text = font.render(str(env[1][pa]), True, (255,255,255) )\n",
    "        gameDisplay.blit(text, ((j+0.3)*tile_size,(i+0.25)*tile_size))\n",
    "        font = pygame.font.SysFont('CFF', 30)\n",
    "        text = font.render(str(pa_to_n[pa]), True, (255,0,0) )\n",
    "        gameDisplay.blit(text, (j*tile_size,i*tile_size))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if [i,j] not in occupied:\n",
    "                gameDisplay.blit(grass, (j*tile_size,i*tile_size))\n",
    "    #Description:\n",
    "    i = 40\n",
    "    pygame.draw.rect(gameDisplay, (0,0,0), (1010,i-15,1000,i+10),0)\n",
    "    font = pygame.font.SysFont('CFF', 32)\n",
    "    text = font.render('Time step:  ' + str(time_step), True, (255,160,0) )\n",
    "    gameDisplay.blit(text, (1050, i))\n",
    "    i = 130\n",
    "    font = pygame.font.Font('freesansbold.ttf', 30)\n",
    "    text = font.render('INSPECTOR CHARGES:', True, (101,67,33), (255,255,255))\n",
    "    gameDisplay.blit(text, (1045,i))\n",
    "    i = 180\n",
    "    \n",
    "    for insp in [rob for rob in env[0] if env[0][rob][3] == 'i']:\n",
    "        font = pygame.font.Font('freesansbold.ttf', 18)\n",
    "        text = font.render( str(insp)[-1] + \" inspector's charge = \" + str(env[0][insp][2]), True, (101,67,33) )\n",
    "        gameDisplay.blit(text, (1045,i))\n",
    "        i += 35\n",
    "        \n",
    "    \n",
    "    \n",
    "def display_actions(game_actions, gameDisplay):\n",
    "    i = 300\n",
    "    font = pygame.font.Font('freesansbold.ttf', 30)\n",
    "    text = font.render('PRESS A NUMBER:', True, (101,67,33), (255,255,255))\n",
    "    gameDisplay.blit(text, (1045,i))\n",
    "    i = 350\n",
    "    for testo in game_actions:\n",
    "        font = pygame.font.Font('freesansbold.ttf', 18)\n",
    "        text = font.render(testo, True, (101,67,33), (255,255,255))\n",
    "        gameDisplay.blit(text, (1045,i))\n",
    "        i += 35\n",
    "        \n",
    "def display_finish(human_score, machine_score, gameDisplay, image_edge = 1000):\n",
    "        if human_score > machine_score:\n",
    "            q = '   >   '\n",
    "            testol = '- You won -'\n",
    "        else:\n",
    "            q = '   <   '\n",
    "            testol = '- The machine won -'\n",
    "        \n",
    "        gameDisplay.fill((0, 0, 0))\n",
    "        font = pygame.font.SysFont('CFF', 40)\n",
    "        \n",
    "        \n",
    "        testo = '***********************************************************************************'\n",
    "        text = font.render(testo, True, (255,255,52) )\n",
    "        text_rect = text.get_rect(center=(3*image_edge/4, image_edge*0.7/2))\n",
    "        gameDisplay.blit(text, text_rect)\n",
    "        \n",
    "        testo = 'HUMAN  ' + str(human_score) + q + str(machine_score) + '  MACHINE'\n",
    "        text = font.render(testo, True, (255,255,52) )\n",
    "        text_rect = text.get_rect(center=(3*image_edge/4, image_edge*0.8/2))\n",
    "        gameDisplay.blit(text,text_rect)\n",
    "        \n",
    "        testo = '******************************************************************'\n",
    "        text = font.render(testo, True, (255,255,52) )\n",
    "        text_rect = text.get_rect(center=(3*image_edge/4, image_edge*0.9/2))\n",
    "        gameDisplay.blit(text, text_rect)\n",
    "        \n",
    "        text = font.render(testol, True, (255,255,52) )\n",
    "        text_rect = text.get_rect(center=(3*image_edge/4, image_edge*1/2))\n",
    "        gameDisplay.blit(text, text_rect)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sequence(p, actions, max_steps, n, obstacles):\n",
    "    \n",
    "    image_edge = 1000\n",
    "    pygame.init()     \n",
    "    tile_size = image_edge/n\n",
    "    gameDisplay = pygame.display.set_mode((3/2 * image_edge, image_edge ))\n",
    "    pygame.display.set_caption('Multi robot environment')\n",
    "    finished = False\n",
    "    i = 0\n",
    "    while not finished:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                finished = True\n",
    "            if event.type == pygame.KEYDOWN: #pressing any button\n",
    "                if i < len(p)-1:\n",
    "                    i += 1 \n",
    "                    nodo_ = p[i]\n",
    "                    nodo = p[i-1]\n",
    "                    t_ = nodo_.current_t()\n",
    "                    t = nodo.current_t()\n",
    "                    if nodo.is_terminal():\n",
    "                        time.sleep(100)\n",
    "                        pygame.quit()\n",
    "                    if actions:\n",
    "                        action = actions[i-2]\n",
    "                    for j in range(t, min(t_, max_steps)):\n",
    "                        #if i < len(p)-1: \n",
    "                        environment = nodo.current_env(j)\n",
    "                        #Environment displaying:\n",
    "                        print_env(tile_size, environment, j, gameDisplay, n, p[1], obstacles)\n",
    "                        \n",
    "                        #pygame.image.save_extended(gameDisplay, prototipol) \n",
    "                        \n",
    "                        pygame.display.update()\n",
    "                        time.sleep(0.2)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_perform(initial_node, max_steps, n, obstacles, machine_best_score):\n",
    "    \n",
    "    \n",
    "    pa_to_n = initial_node.pa_to_n_()\n",
    "    n_to_pa = initial_node.n_to_pa_()\n",
    "    PA = initial_node.PA_()\n",
    "    robots = initial_node.robots_()\n",
    "    C = initial_node.C_()\n",
    "    grid = initial_node.grid_()\n",
    "    max_steps = initial_node.max_steps_()\n",
    "    \n",
    "    \n",
    "    \n",
    "    image_edge =1000\n",
    "    \n",
    "    pygame.init()     \n",
    "    tile_size = image_edge/n\n",
    "    gameDisplay = pygame.display.set_mode((3/2 * image_edge, image_edge ))\n",
    "    pygame.display.set_caption('Multi robot environment')\n",
    "\n",
    "\n",
    "    nodo = copy.deepcopy(initial_node)\n",
    "    t = nodo.current_t()\n",
    "    finished = False\n",
    "    first_node = True\n",
    "\n",
    "    while not finished:\n",
    "\n",
    "        possible_actions_ = nodo.find_children(0)\n",
    "        possible_actions_ = [m[1:] for m in possible_actions_]\n",
    "        #removing eventual duplicates:\n",
    "        possible_actions = []\n",
    "        for el in possible_actions_:\n",
    "            if el not in possible_actions:\n",
    "                possible_actions.append(el)\n",
    "        \n",
    "        \n",
    "        index = 0\n",
    "        game_actions = []\n",
    "        for action in possible_actions:\n",
    "            if action[1] == 'wait_one':\n",
    "                a = ' waits'\n",
    "            elif action[1] == 0:\n",
    "                a = ' recharges'\n",
    "            else:\n",
    "                a = ' inspects panel ' + str(pa_to_n[n_to_pa[action[1]]])\n",
    "            game_actions.append('Press ' + str(index) + ' ---> ' + ' inspector ' + str(action[0])[-1] + str(a))\n",
    "            index += 1\n",
    "\n",
    "\n",
    "\n",
    "        environment = nodo.current_env(t)\n",
    "        if first_node:\n",
    "            print_env(tile_size, environment, t, gameDisplay, n, initial_node, obstacles)\n",
    "            first_node = False\n",
    "        display_actions(game_actions, gameDisplay)\n",
    "        pygame.display.update()\n",
    "\n",
    "        for event in pygame.event.get():\n",
    "\n",
    "            if event.type == pygame.QUIT:\n",
    "                    pygame.quit()\n",
    "                    sys.exit()\n",
    "\n",
    "\n",
    "            if event.type == pygame.KEYDOWN:         \n",
    "\n",
    "                try:\n",
    "                    chosen_index = int(event.unicode)\n",
    "                    rob, action = possible_actions[chosen_index]\n",
    "                    if action == 'wait_one':\n",
    "                        ti, env, current_insp_robot, current_rech_robot, free_panels, urgencies = nodo.compute_hl(rob, action, wait_one = True)\n",
    "                    else:\n",
    "                        ti, env, current_insp_robot, current_rech_robot, free_panels, urgencies = nodo.compute_hl(rob, action)\n",
    "                    nodo_ = Node(PA, robots, C, grid, max_steps, env, n_to_pa, free_panels, current_insp_robot, current_rech_robot, urgencies, ti)\n",
    "                    #            PA, robots, C, grid, max_steps, env, n_to_pa, free_panels, current_insp_robot, current_rech_robot, urgencies=None, t=None, initializing = False):\n",
    "\n",
    "                    t_ = nodo_.current_t()\n",
    "                    if t_ >= max_steps:\n",
    "                        ##\n",
    "                        human_score = nodo_.reward()\n",
    "                        display_finish(human_score, machine_best_score, gameDisplay)\n",
    "                        pygame.display.update()\n",
    "                        time.sleep(100)\n",
    "                        #sys.exit()\n",
    "                    for j in range(t, min(t_, max_steps)):\n",
    "                        environment = nodo.current_env(j)\n",
    "                        #Environment displaying:\n",
    "                        print_env(tile_size, environment, j, gameDisplay, n, initial_node, obstacles)\n",
    "                        pygame.display.update()\n",
    "                        time.sleep(0.2)\n",
    "                    nodo = copy.deepcopy(nodo_)\n",
    "                    t = nodo_.current_t()\n",
    "\n",
    "                except (ValueError, IndexError): #to be sure that the imput index is correct\n",
    "                    continue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_aux(current_rob, action, nodo, other_actions):\n",
    "    # returns a tuple ([x1, ... , xn], optimal action), where x1,x2, ... are respectively:\n",
    "    # - coordinates and charge of the current available robot\n",
    "    # - coordinates and charge of the other inspecting robots, their current task, number of time steps to finish it\n",
    "    # - coordinates of the rechargers\n",
    "    # - urgencies of the panels.\n",
    "    \n",
    "    t = copy.deepcopy(nodo.current_t())\n",
    "    t = t-1\n",
    "    env = copy.deepcopy(nodo.current_env(t))\n",
    "    x1, x2, x3 = env[0][current_rob][0:3]\n",
    "    x = [x1, x2, x3]\n",
    "    \n",
    "    for r in [r for r in env[0] if r != current_rob and env[0][r][3] == 'i']: #inspectors\n",
    "        a, b, c = env[0][r][0:3]\n",
    "        x = x + [a, b, c]\n",
    "        # if the action is not finished yet and is not a waiting action ('wait_one'):\n",
    "        if other_actions[r][0] != 'wait_one' and other_actions[r][1] - t > 0: \n",
    "            x.append(other_actions[r][0])\n",
    "            x.append(other_actions[r][1]-t)\n",
    "        else: # waiting is coded by the integer len(PA)+1\n",
    "            x = x + [len(env[1])+1,-1]\n",
    "        \n",
    "    for r in [r for r in env[0] if env[0][r][3] == 'r']: #rechargers\n",
    "        a, b = env[0][r][0:2]\n",
    "        x = x + [a, b]\n",
    "        \n",
    "    for pa in env[1]:\n",
    "        x.append(env[1][pa])\n",
    "    \n",
    "    if action == 'wait_one': # waiting is coded by the integer len(PA)+1\n",
    "        action = len(env[1])+1\n",
    "\n",
    "    if action != 'no_action':\n",
    "        return (x, action)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(p, actions, max_steps, train_ratio,  stampa = False):\n",
    "    # This functions returns a list of couples state - optimal moove. \n",
    "    \n",
    "    \n",
    "    current_actions = {}\n",
    "    n_to_pa = p[1].n_to_pa_()\n",
    "    \n",
    "    if stampa:\n",
    "        print('n_to_pa: ', n_to_pa)\n",
    "    \n",
    "    train_oc = []\n",
    "    test_oc = []\n",
    "    \n",
    "    for i in range(1,len(p)):\n",
    "        nodo_ = p[i]\n",
    "        nodo = p[i-1]\n",
    "        t_ = nodo_.current_t()\n",
    "        t = nodo.current_t()\n",
    "\n",
    "\n",
    "        if nodo.is_terminal():\n",
    "            break\n",
    "\n",
    "        for j in range(t,min(t_, max_steps)):\n",
    "\n",
    "            if j == t:\n",
    "                \n",
    "                if stampa:\n",
    "                    print('###################### ',i-1 ,'-th NODE . time step:', j, '######################################') \n",
    "\n",
    "                if i < len(p)-1:\n",
    "                    action = actions[i-2]\n",
    "                    az = copy.copy(action[1])\n",
    "                    \n",
    "                    if az == 'wait_one':\n",
    "                        a = 'waits'\n",
    "                    elif az == 0:\n",
    "                        a = 'recharges'\n",
    "                    else:\n",
    "                        a = 'inspects panel ' + str(n_to_pa[az])\n",
    "\n",
    "                    #IMPORTANT OBS: bisogna cambiare: must wait non viene capito----> check se un'azione non  possibile(--> must wait).\n",
    "                    # scartare tutte le coppie (stato, opt action) dove l'opt action non  fattibile.\n",
    "                    fitt = nodo.current_env(t-1) \n",
    "                    if a not in ['waits', 'recharges'] and fitt[0][action[0]][2] == 0:\n",
    "                        az = 0\n",
    "                        a = 'waits'\n",
    "                    \n",
    "                    if stampa:\n",
    "                        print('CURRENT ACTION: ', action[0], a)\n",
    "                    \n",
    "                    # STORING:  current_actions is a dictionary, \n",
    "                    #           key:robot, value:(action, how many time steps to complete it)\n",
    "\n",
    "                    previs = nodo.current_env(t)\n",
    "                    durata = 0\n",
    "                    while action[0] in previs[0]:\n",
    "                        durata += 1\n",
    "                        previs = nodo.current_env(t + durata)\n",
    "\n",
    "                    current_actions[action[0]] = [az , t + durata]    \n",
    "                    \n",
    "                    if stampa:\n",
    "                        for r in current_actions:\n",
    "                            if current_actions[r][1] - t > 0: # l'azione non  ancora finita:\n",
    "                                print('azione corrente di ', r, '  :', current_actions[r][0], ' e durer ancora'\n",
    "                                      , current_actions[r][1] - t)\n",
    "                            else:\n",
    "                                print(r, 'sta aspettando istruzioni')\n",
    "\n",
    "\n",
    "                    try: # we need to skip the first time steps where current_actions is not completed yet\n",
    "                        momentaneo = convert_aux(action[0], az, nodo, current_actions)\n",
    "                        \n",
    "                        if random.random() > train_ratio:\n",
    "                            train_oc.append(momentaneo)\n",
    "                        else:\n",
    "                            test_oc.append(momentaneo)\n",
    "                            \n",
    "                        if stampa:\n",
    "                            print('to store: ',momentaneo)\n",
    "                    except KeyError:\n",
    "                        if stampa:\n",
    "                            print('current_actions not yet completed')\n",
    "                        continue\n",
    "\n",
    "            s = nodo.current_env(j)\n",
    "            \n",
    "            if stampa:\n",
    "                print('PANELS:', s[1])\n",
    "                print('ROBOTS:', s[0])\n",
    "                nodo.visualize(j)\n",
    "                print('          ')\n",
    "\n",
    "                \n",
    "            #CHECKING ERRORS \n",
    "            if j < max_steps-1:\n",
    "                if j == t_- 1:\n",
    "                    s_f = nodo_.current_env(t_)\n",
    "                else:\n",
    "                    s_f = nodo.current_env(j+1) \n",
    "                for r in s[0]:\n",
    "                    if s[0][r][0:2] != s_f[0][r][0:2]:\n",
    "                        if not nodo.be_neighbours(s[0][r][0:2], s_f[0][r][0:2]): # a robot does more than one step\n",
    "                            print(r)\n",
    "                            print('ERROR1: a robot does more than one step')\n",
    "                            #sys.exit()  \n",
    "                            return\n",
    "                        if s[0][r][2] == 0:  # a discharged robot mooves\n",
    "                            print(r)\n",
    "                            print('ERROR4: a discharged robot mooves')\n",
    "                            #sys.exit()\n",
    "                            return\n",
    "                for pa in s[1]:\n",
    "                    if s_f[1][pa] - s[1][pa] > 1:  # a panel urgency increases of more than one unit per time step\n",
    "                        print('ERROR2: a panel urgency increases of more than one unit per time step')\n",
    "                        #sys.exit()\n",
    "                        return\n",
    "                    if s[1][pa] == 0: # a non inspected panel's urgency becomes 0\n",
    "                        if [r for r in s[0] if s[0][r][3] == 'i' and nodo.be_neighbours(s[0][r][0:2], pa)] == []:\n",
    "                            print('ERROR3: a non inspected panel s urgency becomes 0')\n",
    "                            #sys.exit()\n",
    "                            return\n",
    "\n",
    "    return train_oc, test_oc\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_all(DB):\n",
    "    train_oc = []\n",
    "    test_oc = []\n",
    "    pickling_on = open(str(DB)+\"_train.pickle\",\"wb\")\n",
    "    pickle.dump(train_oc, pickling_on)\n",
    "    pickling_on.close()\n",
    "    pickling_on = open(str(DB)+\"_test.pickle\",\"wb\")\n",
    "    pickle.dump(test_oc, pickling_on)\n",
    "    pickling_on.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_couples(p, actions, max_steps, train_ratio, DB):\n",
    "    \n",
    "    new_train_oc, new_test_oc = convert(p, actions, max_steps, train_ratio)\n",
    "    try: \n",
    "        # adjourining:\n",
    "        pickle_off = open(str(DB)+\"_train.pickle\", 'rb')\n",
    "        train_oc = pickle.load(pickle_off)\n",
    "        train_oc += new_train_oc\n",
    "        \n",
    "        pickle_off = open(str(DB)+\"_test.pickle\", 'rb')\n",
    "        test_oc = pickle.load(pickle_off)\n",
    "        test_oc += new_test_oc\n",
    "        \n",
    "    except FileNotFoundError: #if it's the 1st time ---> create the DB\n",
    "        train_oc = new_train_oc\n",
    "        test_oc = new_test_oc\n",
    "        \n",
    "    # pickling:\n",
    "    pickling_on = open(str(DB)+\"_train.pickle\", \"wb\")\n",
    "    pickle.dump(train_oc, pickling_on)\n",
    "    pickling_on.close()\n",
    "\n",
    "    pickling_on = open(str(DB)+\"_test.pickle\",\"wb\")\n",
    "    pickle.dump(test_oc, pickling_on)\n",
    "    pickling_on.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enlarge_DB(C, n, PA, obstacles, robots, max_steps,\n",
    "               n_rollouts, alpha, k, disp, DB, NN_game_rate = 0.9, NN_mooves_rate = 0.9,\n",
    "               model = None, train_ratio = 0.3):\n",
    "    \n",
    "    it = 0\n",
    "    while it < k-1:\n",
    "        \n",
    "        try:\n",
    "            tree = MCTS()\n",
    "            if model:\n",
    "                initial_node, other_actions = initialize_random(tree, C, n, PA, obstacles, robots,\n",
    "                                                                max_steps, with_current_actions = True)\n",
    "                p, actions, scores = do_rollout(initial_node, n_rollouts, alpha, other_actions,\n",
    "                                                True, model, NN_game_rate = NN_game_rate,\n",
    "                                                NN_mooves_rate = NN_mooves_rate, disp = disp, pickling = False)\n",
    "            else:\n",
    "                initial_node = initialize_random(tree, C, n, PA, obstacles, robots, max_steps)       \n",
    "                p, actions, scores = do_rollout(initial_node, n_rollouts, alpha, disp)\n",
    "            store_couples(p, actions, max_steps, train_ratio, DB)\n",
    "            \n",
    "            it += 1\n",
    "            print('ITERATION ', it, 'COMPLETED')\n",
    "\n",
    "        except (IndexError, ValueError, KeyError, TypeError): \n",
    "            #print(traceback.format_exc())\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DB_display(DB, first_50 = False):\n",
    "    pickle_off = open(str(DB)+\"_train.pickle\", 'rb')\n",
    "    train_oc = pickle.load(pickle_off)\n",
    "    pickle_off = open(str(DB)+\"_test.pickle\", 'rb')\n",
    "    test_oc = pickle.load(pickle_off)\n",
    "    print('Train set dimension: ', len(train_oc))\n",
    "    print('Test set dimension: ', len(test_oc))\n",
    "    if first_50:\n",
    "        print('50 train set examples: ')\n",
    "        print(train_oc[:50])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test_set(DB):\n",
    "    \n",
    "    \n",
    "    pickle_off = open(str(DB)+\"_train.pickle\", 'rb')\n",
    "    train_oc = pickle.load(pickle_off)\n",
    "    pickle_off = open(str(DB)+\"_test.pickle\", 'rb')\n",
    "    test_oc = pickle.load(pickle_off)\n",
    "    n_labels = max([s[1] for s in train_oc]) # Ignoring the 'wait' option (that is coded as the last one).\n",
    "    \n",
    "    '''\n",
    "    X_train = [s[0] for s in train_oc if s[1] != n_labels]\n",
    "    Y_train = [s[1] for s in train_oc if s[1] != n_labels]\n",
    "    X_test = [s[0] for s in test_oc if s[1] != n_labels]\n",
    "    Y_test = [s[1] for s in test_oc if s[1] != n_labels]\n",
    "    '''\n",
    "    \n",
    "    min_size_train = min( [len([s[0] for s in train_oc if s[1]==j]) for j in range(n_labels)] ) \n",
    "    min_size_test = min( [len([s[0] for s in test_oc if s[1]==j]) for j in range(n_labels)] )\n",
    "    \n",
    "    \n",
    "    added_train, added_test = np.zeros(n_labels), np.zeros(n_labels)\n",
    "    X_train, Y_train, X_test, Y_test = [], [], [], []\n",
    "    \n",
    "    \n",
    "    for i in range(len(train_oc)):\n",
    "        \n",
    "        if train_oc[i][1] < n_labels and added_train[train_oc[i][1]] < min_size_train:\n",
    "            X_train.append(train_oc[i][0])\n",
    "            Y_train.append(train_oc[i][1])\n",
    "            added_train[train_oc[i][1]] += 1\n",
    "    \n",
    "    for i in range(len(test_oc)):\n",
    "        \n",
    "        if test_oc[i][1] < n_labels and added_test[test_oc[i][1]] < min_size_test:\n",
    "            X_test.append(test_oc[i][0])\n",
    "            Y_test.append(test_oc[i][1])\n",
    "            added_test[test_oc[i][1]] += 1\n",
    "    \n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train, Y_train, X_test, Y_test, Y_test1, EPOCHS = 200,\n",
    "                 shape = [30,100,50],\n",
    "                 activation_functions = ['LeakyReLU', 'LeakyReLU'],\n",
    "                 batch_size = 16, dropout = 0.1, learning_rate = 0.00015):\n",
    "\n",
    "    if len(shape) != len(activation_functions)+1:\n",
    "        print('Error in the architecture, must be len(shape) = len(activation_functions)+1')\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(shape[0], input_shape = (X_train.shape[1],)))    # Input layer => input_shape must be explicitly designated       \n",
    "    model.add(Dropout(dropout), )\n",
    "    \n",
    "    for i in range(len(activation_functions)):\n",
    "\n",
    "        model.add(Dense(shape[i+1], activation = activation_functions[i]))    # Input layer => input_shape must be explicitly designated       \n",
    "        model.add(Dropout(dropout), )\n",
    "    \n",
    "    model.add(Dense(Y_train.shape[1], activation='softmax'))                          # Output layer => output dimension = 1 since it is a regression problem\n",
    "    model.add(Dropout(dropout), )\n",
    "    \n",
    "    # Activation: sigmoid, softmax, tanh, relu, LeakyReLU. \n",
    "    #Optimizer: SGD, Adam, RMSProp, etc. # https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "    \n",
    "    optimizer = optimizers.Adam(learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy',#from_logits=True),\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy']) # for regression problems, mean squared error (MSE) is often employed\n",
    "    \n",
    "    \n",
    "    #MODEL SUMMARY.\n",
    "    print('Here is a summary of this model: ')\n",
    "    model.summary()\n",
    "    history = model.fit(\n",
    "        X_train, \n",
    "        Y_train,\n",
    "        batch_size = batch_size,\n",
    "        epochs=EPOCHS, \n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        steps_per_epoch = int(X_train.shape[0] / batch_size) ,\n",
    "        validation_data = (X_test, Y_test),   \n",
    "    )\n",
    "\n",
    "    #PLOTS.\n",
    "    #plotting accuracy and loss:\n",
    "    '''plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train', 'Cross-Validation'], loc='upper left')\n",
    "    plt.show()'''\n",
    "    \n",
    "    #plotting the confusion matrix:\n",
    "    ax= plt.subplot()\n",
    "    predict_results = model.predict(X_test)\n",
    "    # predict_results = (predict_results.argmax())\n",
    "    predict_results= predict_results.argmax(axis = 1)\n",
    "    cm = confusion_matrix(Y_test1, predict_results)\n",
    "    sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    # ax.xaxis.set_ticklabels(['Positive', 'Negative']); ax.yaxis.set_ticklabels(['Positive', 'Negative']);\n",
    "\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_plays(model, initial_node, other_actions, NN_mooves_rate = 1):\n",
    "    \n",
    "    node = copy.deepcopy(initial_node)\n",
    "    grid = node.grid_()\n",
    "    n_to_pa = node.n_to_pa_()\n",
    "    PA = node.PA_()\n",
    "    robots = node.robots_()\n",
    "    C = node.C_()\n",
    "    max_steps = node.max_steps_()\n",
    "    n_labels = len(PA)+1\n",
    "    \n",
    "    #PA, robots, C, grid, max_steps, env, n_to_pa,\n",
    "    #free_panels, current_insp_robot, current_rech_robot, urgencies, ti)\n",
    "\n",
    "    nodes_sequence = []\n",
    "    actions_sequence = []\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        current_robots = node.current_insp()\n",
    "        rob = current_robots[0]\n",
    "\n",
    "        x = convert_aux(rob, 'no_action', node, other_actions)\n",
    "        \n",
    "        if random.random() < NN_mooves_rate:\n",
    "        \n",
    "            # transforming x so that it is readable by model.predict:\n",
    "            a = {}\n",
    "            for i in range(len(x)):\n",
    "                a[i] = [x[i]]\n",
    "            c = pd.DataFrame(a)\n",
    "            prob = model.predict(c)\n",
    "            prob = prob[0]\n",
    "            \n",
    "        else:\n",
    "            prob = [random.random() for _ in range(n_labels)]\n",
    "        \n",
    "        \n",
    "        possible_actions = node.find_children(0)   \n",
    "        possible_actions = [m[1:] for m in possible_actions if m[1] == rob] #(n_of_children,rob,action)--->(rob,action)\n",
    "\n",
    "        while True:\n",
    "\n",
    "            if sum(prob) == 0: #then 'wait_one' \n",
    "                ti, env, current_insp_robot, current_rech_robot, free_panels, urgencies = node.compute_hl(rob, action, wait_one = True)\n",
    "                node_ = Node(PA, robots, C, grid, max_steps, env, n_to_pa, free_panels, current_insp_robot, current_rech_robot, urgencies, ti)\n",
    "                nodes_sequence.append(node)\n",
    "                actions_sequence.append((rob, 'wait_one'))\n",
    "                \n",
    "                #adjourning other_actions\n",
    "                t = node.current_t()\n",
    "                previs = node.current_env(t)\n",
    "                durata = 0\n",
    "                while rob in previs[0]:\n",
    "                    durata += 1\n",
    "                    previs = node.current_env(t + durata)\n",
    "                other_actions[rob] = [action , t + durata]\n",
    "\n",
    "                break \n",
    "\n",
    "            action = np.argmax(prob) #choosing the best action\n",
    "\n",
    "            if (rob, action) in possible_actions:\n",
    "\n",
    "                try:\n",
    "                    copia = node.make_copy()\n",
    "                    ti, env, current_insp_robot, current_rech_robot, free_panels, urgencies = copia.compute_hl(rob, action)\n",
    "                    node_ = Node(PA, robots, C, grid, max_steps, env, n_to_pa, free_panels, current_insp_robot, current_rech_robot, urgencies, ti)\n",
    "\n",
    "                    #adjourning other_actions\n",
    "                    t = copia.current_t()\n",
    "                    previs = copia.current_env(t)\n",
    "                    durata = 0\n",
    "                    while rob in previs[0]:\n",
    "                        durata += 1\n",
    "                        previs = copia.current_env(t + durata)\n",
    "                    other_actions[rob] = [action , t + durata]\n",
    "                    nodes_sequence.append(copia)\n",
    "                    actions_sequence.append((rob,action))\n",
    "                    break\n",
    "\n",
    "                except (ValueError, IndexError):\n",
    "                    prob[action] = 0\n",
    "\n",
    "            else:\n",
    "                prob[action] = 0\n",
    "\n",
    "        if node_ == 'error':\n",
    "            break\n",
    "\n",
    "        if node.is_terminal(): \n",
    "            reward = node_.reward()\n",
    "            break\n",
    "\n",
    "        node = copy.deepcopy(node_)\n",
    "\n",
    "    return nodes_sequence, actions_sequence, reward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_agent(initial_node, iterations, machine_score,  disp):\n",
    "    scores = []\n",
    "\n",
    "    while len(scores) < iterations:\n",
    "        node = copy.deepcopy(initial_node)\n",
    "\n",
    "        while True:\n",
    "            node_ = copy.deepcopy(node.find_random_child())\n",
    "            if node_ == 'error':\n",
    "                break\n",
    "            if node_.is_terminal(): \n",
    "                reward = node_.reward()\n",
    "                scores.append(reward)\n",
    "                break\n",
    "            node = copy.deepcopy(node_)\n",
    "        if disp != None and len(scores) % disp == 0:\n",
    "            print(str(len(scores)) + ' random games simulated, best score achieved: '\n",
    "                  + str(max(scores)) + ', mean: ' + str(np.mean(scores)))\n",
    "    \n",
    "    print('Scores mean:',np.mean(scores))\n",
    "    print('Best score:',max(scores))\n",
    "    \n",
    "    if machine_score:\n",
    "        pepe = len([s for s in scores if s > machine_score])/iterations*100\n",
    "        print('Percentage of better random games:', pepe, ' %')\n",
    "        \n",
    "    plt.plot(scores, \"o\", markersize = 0.85)\n",
    "    if machine_score:\n",
    "        plt.axhline(y = machine_score)\n",
    "    plt.title(\"Scores\")\n",
    "    plt.xlabel('rollout number')\n",
    "    plt.ylabel('Score')\n",
    "    plt.show()\n",
    "    #print('best random result:',max(scores), 'over a total of ', len(scores), 'random trials')\n",
    "    #if machine_score:\n",
    "    #    return pepe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(models, iterations, C, n, PA, obstacles, robots, max_steps):\n",
    "    \n",
    "    model_scores = {}\n",
    "    model_wins = {}\n",
    "    \n",
    "    for model in models:\n",
    "        model_scores[model] = 0\n",
    "        model_wins[model] = 0\n",
    "        \n",
    "    it = 0\n",
    "    while it < iterations:\n",
    "        \n",
    "        try:\n",
    "            tree = MCTS()\n",
    "            initial_node, other_actions = initialize_random(tree, C, n, PA, obstacles, \n",
    "                                                               robots, max_steps, with_current_actions = True)\n",
    "            scores = {}\n",
    "            for model in models:\n",
    "                p, actions_sequence, score = NN_plays(model, initial_node, other_actions, NN_mooves_rate = 1)\n",
    "                scores[model] = score\n",
    "            for model in models:\n",
    "                model_scores[model] += scores[model]\n",
    "            winning_model = max(scores.items(), key=operator.itemgetter(1))\n",
    "            model_wins[winning_model[0]] += 1\n",
    "                \n",
    "        except (IndexError, ValueError, KeyError, TypeError):\n",
    "            continue\n",
    "        it += 1    \n",
    "                \n",
    "        if it % 10 == 0:\n",
    "            print('Iteration '+ str(it) +' completed.')\n",
    "    \n",
    "    n_mod = 0\n",
    "    for model in models:\n",
    "        n_mod += 1\n",
    "        print('Model '+str(n_mod)+' average score: '+str(model_scores[model]/iterations)\n",
    "              +', best model in '+str(model_wins[model])+' iterations.')\n",
    "        \n",
    "    \n",
    "            \n",
    "           \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/royjafari/DataAnalyticsForFun/blob/main/MLP%20Classification/MLP%20Classify%20-%20E.ipynb\n",
    "\n",
    "https://github.com/zhailat/Introduction-to-machine-learning-Python/blob/master/Part%2007%20-%20Constructing%20a%20Multi-Class%20Classifier%20Using%20Neural%20Network%20with%20Python%20(Tensorflow%20%26%20Keras)/Ex04-NN-multi-class.ipynb\n",
    "\n",
    "https://www.youtube.com/watch?v=oOSXQP7C7ck"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
